{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.model_zoo as model_zoo\n\n\n__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n           'resnet152']\n\nmodel_urls = {\n    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n}\n\nclass Normalize(nn.Module):\n\n    def __init__(self, power=2):\n        super(Normalize, self).__init__()\n        self.power = power\n    \n    def forward(self, x):\n        norm = x.pow(self.power).sum(1, keepdim=True).pow(1./self.power)\n        out = x.div(norm)\n        return out\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, low_dim=128):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n        self.fc = nn.Linear(512 * block.expansion, low_dim)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        #x = self.fc(x)\n        x = F.normalize(x)\n        return x\n\n\ndef resnet18(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n    return model\n\n\ndef resnet34(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n    return model\n\n\ndef resnet50(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n    return model\n\n\ndef resnet101(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n    return model\n\n\ndef resnet152(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:07:55.254757Z","iopub.execute_input":"2022-09-17T14:07:55.255184Z","iopub.status.idle":"2022-09-17T14:07:56.987599Z","shell.execute_reply.started":"2022-09-17T14:07:55.255092Z","shell.execute_reply":"2022-09-17T14:07:56.986611Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"availableBackends = {'resnet18':resnet18, 'resnet34':resnet34, 'resnet50':resnet50, 'resnet101':resnet101,'resnet152':resnet152}\n\nclass MLP(nn.Module):\n    def __init__(self,\n    input_size = 2048,\n    hidden_size = 4096,\n    output_size = 256,\n    depth = 2,\n    ):  \n        super().__init__()\n        layers = []\n        inp = input_size\n        for d in range(depth):\n            if d == depth - 1:\n                layers.append(nn.Linear(inp, output_size))\n            else:\n                layers.extend([nn.Linear(inp, hidden_size), nn.BatchNorm1d(hidden_size), nn.ReLU(inplace=True)])\n                inp = hidden_size\n        self.layer = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.layer(x)\n\nclass OnlineNetwork(nn.Module):\n    def __init__(self,\n    input_size=2048,\n    hidden_size=4096,\n    output_size=256,\n    depth_proj=2,\n    depth_pred=2,\n    closedFormPredicator = False,\n    backend = 'resnet50',\n    pretrained = False):\n        super().__init__()\n        self.backend = availableBackends[backend](pretrained=pretrained)\n        self.projection = MLP(input_size = input_size, output_size = output_size, hidden_size = hidden_size, depth = depth_proj)\n        self.predictor = None\n\n        if not closedFormPredicator:\n            self.predictor = MLP(input_size=output_size, output_size = output_size, hidden_size = hidden_size, depth = depth_pred)\n\n    def forward(self, x):\n        x = self.backend(x)\n        out = self.projection(x)\n\n        if self.predictor is not None:\n            out = self.predictor(out)\n        \n        return out\n\n\nclass TargetNetwork(nn.Module):\n    def __init__(self,\n    input_size=2048,\n    hidden_size=4096,\n    output_size=256,\n    depth_proj=2,\n    backend = 'resnet50',\n    pretrained = False):\n        super().__init__()\n        self.backend = availableBackends[backend](pretrained=pretrained)\n        self.projection = MLP(input_size = input_size, output_size = output_size, hidden_size = hidden_size, depth = depth_proj)\n        self.predictor = None\n\n\n        for model in [self.backend, self.projection]:\n            for p in model.parameters():\n                p.requires_grad = False\n\n    def forward(self, x):\n        out = self.backend(x)\n        out = self.projection(out)\n        return out\n\nclass BYOL(nn.Module):\n    def __init__(self,\n    input_size=2048,\n    hidden_size=4096,\n    output_size=256,\n    depth_proj=2,\n    depth_pred=2,\n    closedFormPredicator = False,\n    EMA = True,\n    t = 0.996,\n    backend='resnet50',\n    pretrained = False):\n        super().__init__()\n        self.t = t\n        self.EMA = EMA\n        self.closedForm = closedFormPredicator\n        self.onlineNet = OnlineNetwork(input_size=input_size, hidden_size=hidden_size, output_size=output_size, \n        depth_proj= depth_proj, depth_pred=depth_pred, closedFormPredicator = closedFormPredicator, backend=backend, pretrained=pretrained)\n        self.targetNet = TargetNetwork(input_size=input_size, hidden_size=hidden_size, output_size=output_size, depth_proj=depth_proj, backend=backend, pretrained=pretrained)\n\n    def updateTargetNetwork(self, lamb = 10):\n        with torch.no_grad():\n            for pOn,pTa in zip(self.onlineNet.parameters(), self.targetNet.parameters()):\n                if self.EMA and not self.closedForm :\n                    pTa = self.t*pTa + (1-self.t)*pOn\n                else:\n                    pTa = lamb*pOn\n\n    def forward(self, x, y):\n        xOn = self.onlineNet(x)\n        yOn = self.onlineNet(y)\n        xTg = self.targetNet(x)\n        yTg = self.targetNet(y)\n\n        if self.closedForm:\n            xOn = (xOn.T@yTg)/(xOn.T@xOn)\n            yOn = (yOn.T@xTg)/(yOn.T@yOn)\n\n        return xOn, yOn, xTg, yTg","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:07:56.989675Z","iopub.execute_input":"2022-09-17T14:07:56.990250Z","iopub.status.idle":"2022-09-17T14:07:57.010688Z","shell.execute_reply.started":"2022-09-17T14:07:56.990196Z","shell.execute_reply":"2022-09-17T14:07:57.009696Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms as tr\n\ndef regression_loss(x, y):\n    x = F.normalize(x, dim=1, p=2)\n    y = F.normalize(y, dim=1, p=2)\n    return 2 - 2 * (x*y).sum(dim=-1)\n\ndef criterion(xOn, yTg, yOn, xTg):\n    return (regression_loss(xOn, yTg) + regression_loss(yOn, xTg)).mean()\n\n\ndef get_byol_transforms(size, mean, std):\n    transformT = tr.Compose([\n    tr.RandomResizedCrop(size=size, scale=(0.08,1), ratio=(3 / 4, 4 / 3)),\n    tr.RandomApply(nn.ModuleList([tr.RandomRotation((-90, 90))]), p=0.5),\n    tr.RandomApply(nn.ModuleList([tr.ColorJitter()]), p=0.8),\n    tr.GaussianBlur(kernel_size=(23,23), sigma=(0.1, 2.0)),\n    #tr.RandomGrayscale(p=0.2),\n    tr.Normalize(mean, std)])\n\n    transformT1 = tr.Compose([\n        tr.RandomResizedCrop(size=size, scale=(0.08,1), ratio=(3 / 4, 4 / 3)),\n        tr.RandomApply(nn.ModuleList([tr.RandomRotation((-90, 90))]), p=0.5),\n        tr.RandomApply(nn.ModuleList([tr.ColorJitter()]), p=0.8),\n        #tr.RandomGrayscale(p=0.2),\n        tr.RandomApply(nn.ModuleList([tr.GaussianBlur(kernel_size=(23,23), sigma=(0.1, 2.0))]), p=0.1),\n        tr.Normalize(mean, std)])\n\n    transformEvalT = tr.Compose([\n        tr.CenterCrop(size=size),\n        tr.Normalize(mean, std)\n    ])\n\n    return transformT, transformT1, transformEvalT","metadata":{"execution":{"iopub.status.busy":"2022-09-17T15:45:28.813334Z","iopub.execute_input":"2022-09-17T15:45:28.814219Z","iopub.status.idle":"2022-09-17T15:45:28.825985Z","shell.execute_reply.started":"2022-09-17T15:45:28.814182Z","shell.execute_reply":"2022-09-17T15:45:28.825034Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nimport torchvision.transforms as tr\nimport torchvision.datasets as datasets\nimport numpy as np\nfrom tqdm import tqdm\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\nepochs = 30\nbatch_size = 512\noffset_bs = 256\nbase_lr = 0.03\ntempBase = 0.996\n\ntransformT, transformT1, transformEvalT = get_byol_transforms(32, (0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n\n#traindt = datasets.ImageNet(root='./data', split = 'train')\n#trainloader = torch.utils.data.DataLoader(traindt, batch_size=batch_size, shuffle=True)\n\n#testdt = datasets.ImageNet(root='./data', split = 'val')\n#testloader = torch.utils.data.DataLoader(traindt, batch_size=128, shuffle=True)\n\ntrainset = datasets.STL10(root='./', split='unlabeled', transform=tr.ToTensor(), download=True)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n\nlr = base_lr*batch_size/offset_bs\n\nbyol = BYOL(input_size=512, closedFormPredicator=False, backend='resnet34')\n\nbyol.to(device)\n\nparams = byol.parameters()\noptimizer = optim.SGD( params, lr=lr, weight_decay=1.5e-4)\n\ndef train_loop(model, optimizer, trainloader, transform, transform1, criterion, device):\n    tk0 = tqdm(trainloader)\n    train_loss = []\n    var_loss = []\n\n    for batch, inf in tk0:\n        #print(inf)\n        batch = batch.to(device)\n        \n        x = transform(batch)\n        x1 = transform1(batch)\n\n        onlinex, onlinex1, targetx, targetx1 = model(x, x1)\n        loss = criterion(onlinex, targetx1, onlinex1, targetx)\n        train_loss.append(loss.item())\n        with torch.no_grad():\n          var_online = onlinex.var(dim=0).mean()\n          var_target = targetx.var(dim=0).mean()\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        byol.updateTargetNetwork()\n        tk0.set_description(f\"the variance in online: {var_online} Variance target: {var_target}\")\n\n        del batch, x, x1, onlinex, onlinex1, targetx, targetx1\n    return train_loss\n\n\nfor epoch in range(epochs):\n    train_loss = train_loop(byol, optimizer, trainloader, transformT, transformT1, criterion, torch.device('cuda'))\n    print(f\"Epoch: {epoch} train_loss: {np.mean(train_loss)}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-09-17T15:45:29.486310Z","iopub.execute_input":"2022-09-17T15:45:29.486997Z","iopub.status.idle":"2022-09-17T16:52:40.965865Z","shell.execute_reply.started":"2022-09-17T15:45:29.486961Z","shell.execute_reply":"2022-09-17T16:52:40.964840Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.25450727343559265 Variance target: 0.10934548825025558: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 0 train_loss: 1.725413658789226\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.2922554612159729 Variance target: 0.10910944640636444: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1 train_loss: 1.685900741693925\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.30020058155059814 Variance target: 0.11065667122602463: 100%|██████████| 196/196 [02:13<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 2 train_loss: 1.680986790632715\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.37627002596855164 Variance target: 0.1092851459980011: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 3 train_loss: 1.676194657476581\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.3727826476097107 Variance target: 0.1094784140586853: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 4 train_loss: 1.672424363238471\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.3674464225769043 Variance target: 0.10884768515825272: 100%|██████████| 196/196 [02:13<00:00,  1.46it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 5 train_loss: 1.6719406210646337\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.43514135479927063 Variance target: 0.1097947508096695: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 6 train_loss: 1.6692971112776775\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.4165436327457428 Variance target: 0.1090916320681572: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 7 train_loss: 1.6718153412244758\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.3948100209236145 Variance target: 0.10986348241567612: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 8 train_loss: 1.6706934376638762\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.4815174341201782 Variance target: 0.11026087403297424: 100%|██████████| 196/196 [02:14<00:00,  1.45it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 9 train_loss: 1.6696698756850497\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.4294852316379547 Variance target: 0.10953722894191742: 100%|██████████| 196/196 [02:15<00:00,  1.45it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10 train_loss: 1.6686153782873738\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.533801794052124 Variance target: 0.10973526537418365: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 11 train_loss: 1.669242642971934\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.5275633335113525 Variance target: 0.10978277027606964: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 12 train_loss: 1.6671498034681593\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.6080265641212463 Variance target: 0.11011865735054016: 100%|██████████| 196/196 [02:13<00:00,  1.46it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 13 train_loss: 1.6692583725160481\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.48905712366104126 Variance target: 0.10983026027679443: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 14 train_loss: 1.6678252402617006\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.5548251867294312 Variance target: 0.10965742915868759: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 15 train_loss: 1.667565288592358\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.5316743850708008 Variance target: 0.1092541515827179: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 16 train_loss: 1.6682800352573395\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.5390341281890869 Variance target: 0.11100880801677704: 100%|██████████| 196/196 [02:13<00:00,  1.46it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 17 train_loss: 1.6671924244384377\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.5860195159912109 Variance target: 0.11018182337284088: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 18 train_loss: 1.6658149039258763\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.5063384771347046 Variance target: 0.10919936001300812: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 19 train_loss: 1.6663569430915677\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.5649709701538086 Variance target: 0.10916338860988617: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 20 train_loss: 1.66568246666266\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.6616073250770569 Variance target: 0.11065647751092911: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 21 train_loss: 1.6660600912814238\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.47974056005477905 Variance target: 0.11039433628320694: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 22 train_loss: 1.66544793272505\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.5722675323486328 Variance target: 0.11003349721431732: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 23 train_loss: 1.665418349966711\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.659061074256897 Variance target: 0.1093657910823822: 100%|██████████| 196/196 [02:13<00:00,  1.46it/s]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 24 train_loss: 1.666944949602594\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.5149409770965576 Variance target: 0.11021195352077484: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 25 train_loss: 1.6663263008302571\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.542673647403717 Variance target: 0.11010409891605377: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 26 train_loss: 1.6666038626310777\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.5729129314422607 Variance target: 0.10992155224084854: 100%|██████████| 196/196 [02:14<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 27 train_loss: 1.6655894311106936\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.481828510761261 Variance target: 0.1090821921825409: 100%|██████████| 196/196 [02:13<00:00,  1.46it/s]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 28 train_loss: 1.6638259620082623\n","output_type":"stream"},{"name":"stderr","text":"the variance in online: 0.5968812704086304 Variance target: 0.10986419767141342: 100%|██████████| 196/196 [02:13<00:00,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 29 train_loss: 1.6667980819332355\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"class LogisticRegression(nn.Module):\n    def __init__(self, encoder, input_size, output_size):\n        super().__init__()\n        \n        self.encoder = encoder\n        self.linear = nn.Linear(input_size, output_size)\n        \n        for p in self.encoder.parameters():\n            p.required_grad = False\n        \n    \n    def forward(self, x):\n        self.encoder.eval()\n        x = self.encoder(x)\n        x = self.linear(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2022-09-17T17:11:12.033461Z","iopub.execute_input":"2022-09-17T17:11:12.033848Z","iopub.status.idle":"2022-09-17T17:11:12.041210Z","shell.execute_reply.started":"2022-09-17T17:11:12.033818Z","shell.execute_reply":"2022-09-17T17:11:12.040297Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"trainset = datasets.STL10(root='./', split='train', transform=tr.ToTensor(), download=True)\ntrain_loader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True)\n\ntestset = datasets.STL10(root='./', split='test', transform=tr.ToTensor(), download=True)\ntest_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n\nmodel = LogisticRegression(byol.onlineNet.backend, 512, 10).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-09-17T17:13:43.560687Z","iopub.execute_input":"2022-09-17T17:13:43.561062Z","iopub.status.idle":"2022-09-17T17:13:54.891094Z","shell.execute_reply.started":"2022-09-17T17:13:43.561034Z","shell.execute_reply":"2022-09-17T17:13:54.890144Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\ncriterion = torch.nn.CrossEntropyLoss()\neval_every_n_epochs = 10\n\nfor epoch in range(200):\n#     train_acc = []\n    for x, y in train_loader:\n\n        x = x.to(device)\n        y = y.to(device)\n        \n        # zero the parameter gradients\n        optimizer.zero_grad()        \n        \n        logits = model(x)\n        predictions = torch.argmax(logits, dim=1)\n        \n        loss = criterion(logits, y)\n        \n        loss.backward()\n        optimizer.step()\n    \n    total = 0\n    if epoch % eval_every_n_epochs == 0:\n        correct = 0\n        for x, y in test_loader:\n            x = x.to(device)\n            y = y.to(device)\n\n            logits = model(x)\n            predictions = torch.argmax(logits, dim=1)\n            \n            total += y.size(0)\n            correct += (predictions == y).sum().item()\n            \n        acc = 100 * correct / total\n        print(f\"Testing accuracy: {np.mean(acc)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-17T17:13:54.893561Z","iopub.execute_input":"2022-09-17T17:13:54.894121Z","iopub.status.idle":"2022-09-17T17:14:53.096558Z","shell.execute_reply.started":"2022-09-17T17:13:54.894084Z","shell.execute_reply":"2022-09-17T17:14:53.094935Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Testing accuracy: 85.26\nTesting accuracy: 100.0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_18/2932497884.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     train_acc = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/stl10.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tobytes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2945\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2946\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":" ","metadata":{},"execution_count":null,"outputs":[]}]}